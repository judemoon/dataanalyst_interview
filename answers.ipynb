{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interview Practice for Data Analyst Job \n",
    "\n",
    "August 2017, by Jude Moon\n",
    "\n",
    "## Practice Overview\n",
    "Employers use interviews to judge your readiness and fit for the job, which includes hearing about your skills and interest in the role. The interview is not a test or exam, but a conversation between you and the employer. Build your own strategies to be prepared come interview day. This project is one of many ways for you to practice!\n",
    "\n",
    "### 1. Describe a data project you worked on recently.\n",
    "\n",
    "One of the most challenging projects from the Data Analyst Nanodegree Program was Machine Learning project for detecting fraud from Enron email and financial datasets. It was easy for me to explore and clean the datasets since I already had experience in data exploration from other projects. But the challenge was to figure out where to start among lots of algorithms available. The task was to build a person of interest (POI) identifier based on labeled data. For supervised classification, I found 6 common algorithms from scikit-learn library. I engineered and created 9 feature lists from the original feature list. To compare each pair of feature list and classifier algorithm, I had 60 combinations to test out. \n",
    "\n",
    "I was not sure my computer had enough power to compute all 60 trials at once. So, instead of scripting procedures to perform all, I stepped back and researched the pros, cons, and proper usages of each algorithm. And then I prioritized 3 top algorithms and feature lists. I documented rationale behind the choice of algorithms. I constructed procedures and loops to implement pipeline and gridsearch for selecting features and optimizing hyper-parameters. I finally had a combination giving me good enough performance scores after about 20 trials. It could have been exhausting trial process and could have taken me much longer time, but I could get it done within two days by spending some time to understand the algorithms first.\n",
    "\n",
    "----\n",
    "\n",
    "### 2. You are given a ten piece box of chocolate truffles. You know based on the label that six of the pieces have an orange cream filling and four of the pieces have a coconut filling. If you were to eat four pieces in a row, what is the probability that the first two pieces you eat have an orange cream filling and the last two have a coconut filling?\n",
    "\n",
    "* Probability of 1st and 2nd choices to be orange: $\\frac{6}{10} * \\frac{5}{9}$\n",
    "* Probability of 3rd and 4th choice to be coconut: $\\frac{4}{8} * \\frac{3}{7}$\n",
    "* Probability of 1st and 2nd choices to be orange and 3rd and 4th choice to be coconut: $\\frac{6}{10} * \\frac{5}{9} * \\frac{4}{8} * \\frac{3}{7} = 0.0714$\n",
    "\n",
    "\n",
    "### Follow up question: If you were given an identical box of chocolates and again eat four pieces in a row, what is the probability that exactly two contain coconut filling?\n",
    "\n",
    "* Number of cases to be orange or coconut for 4 pieces: $2 * 2 * 2 * 2 = 16$\n",
    "* Number of combinations to be two coconut and two orange: $(4-1) + (4-2) + (4-3) = 6$\n",
    "* Probability of combinations to be two coconut and two orange: $\\frac{6}{16} =0.375$\n",
    "\n",
    "----\n",
    "\n",
    "### 3. Given the table users:\n",
    "\n",
    "\n",
    "<center>Table \"users\"</center>\n",
    "\n",
    "\n",
    "| Column   | Type      |\n",
    "|----------|-----------|\n",
    "| id       | integer   |\n",
    "| username | character |\n",
    "| email    | character |\n",
    "| city     | character |\n",
    "| state    | character |\n",
    "| zip      | integer   |\n",
    "| active   | boolean   |\n",
    "\n",
    "### Construct a query to find the top 5 states with the highest number of active users. Include the number for each state in the query result.\n",
    "\n",
    "\n",
    "    SELECT state, SUM(active)\n",
    "    from users\n",
    "    GROUP BY state\n",
    "    ORDER BY SUM(active) DESC\n",
    "    LIMIT 5\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "### 4. Define a function first_unique that takes a string as input and returns the first non-repeated (unique) character in the input string. If there are no unique characters return None. Note: Your code should be in Python.\n",
    "\n",
    "```\n",
    "def first_unique(string):\n",
    " # Your code here\n",
    " return unique_char\n",
    "\n",
    "> first_unique('aabbcdd123')\n",
    "> c\n",
    "\n",
    "> first_unique('a')\n",
    "> a\n",
    "\n",
    "> first_unique('112233')\n",
    "> None\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def first_unique(word):\n",
    "    \n",
    "    counts = defaultdict(int) # initiate defaultdict for count \n",
    "    \n",
    "    for c in word:\n",
    "        counts[c] += 1 # add c as a key and number as a value to dictionary\n",
    "      \n",
    "    for c in counts:\n",
    "        if counts[c] == 1: # if the value is 1 (appeared once), return the key\n",
    "            return c\n",
    "    \n",
    "    return \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_unique('aabbcdd123')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_unique('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'None'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_unique('112233')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### 5. What are underfitting and overfitting in the context of Machine Learning? How might you balance them?\n",
    "\n",
    "Both underfitting and overfitting refer poor generalization to new data, but underfitting refers poor performance on the training data as well, while overfitting refers good performance on the training data. Underfitting is easy to be detected by evaluating metrics and it is better to move on and try other algorithms. Overfitting can be controlled by adjusting parameters, so that it limits how much detail and noise in the training data the model would learn.\n",
    "\n",
    "To balance between good performance on training data and unseen data, cross validation can be used. You can separate a subset of your training data and hold back from your machine learning algorithm training and tuning. After finishing selecting and tuning algorithms, you can get evaluation of the algorithm on the subset, which shows a performance on unseen data. But if you have a limited dataset size, such methods like KFold and ShuffleSplit allow to cross evaluate the algorithm on multiple different splitting sets of training and testing data and give average metrics.\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "### 6. If you were to start your data analyst position today, what would be your goals a year from now?\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
